> Gli indici sono strutture dati che accelerano l'accesso (ricerca) di dati, conservate sulla memoria secondaria.

> Gli indici sono strutture dati sopra a un testo (nel nostro caso) che permette di velocizzare la ricerca. Gli indici si costruiscono offline.

Il processo di indicizzazione è un processo separato dal query processing

Gli indici che vengono usati per fare ricerca su dati alfanumerici (ad esempio un codice fiscale) sono chiamati **B+ tree** (*B plus tree*). È la principale tipologia di indice che viene usato per fare ricerche su grandi quantità di dati, perché il costo di accesso è logaritmico (non logaritmo in base due, ma base più alta, che permette performance migliori).

In SQL si costruisce sulle colonne su cui faccio accesso più di frequente.

#x012 Vedi alberi 2-3-4, alberi AVL

L'indicizzazione funziona quando il tasso di modifica della collezione dei dati è di qualche ordine inferiore rispetto al tasso di ricerca: è **semistatica** e di **grandi dimensioni**; ovvero quando il gioco vale la candela. I servizi di streaming non indicizzano.

Tecniche di indicizzazione:
- **inverted indexes**. Composto da vocabolario e occorrenze. Scelta migliore al momento.
- **suffix arrays**. Utilizzati per fare matching di catene proteiche.
- **signature files**. Concorrenti degli inverted indexes ma in disuso.

Cosa dobbiamo considerare?
- search cost +
- space overhead -
- costo di creazione e aggiornamento -

Solitamente il bilancio è positivo per gli inverted indexes.
## Inverted index
> Gli **inverted index** sono dizionari che contengono come chiave una parole e come valore la lista di documenti che la contengono.

## Notazione
- **n** dimensione del text repository. Si ottiene concatenando tutti i caratteri di tutti i token di tutti i documenti contenuti nel database.
- **m** lunghezza della parola da cercare. "letter" è lunga 6
- **M** dimensione della memoria principale, misurata nella stessa unità di misura dei restanti, ad esempio in caratteri.

Costo ricerche:

| nome | costo ricerca | costo inserimento |
|------|---------------|-------------------|
|sorted array|logN|N|
|binary tree|logN|N|
|hash table|1|N|
|B tree|logN|logN|

# Trie o Prefix Tree
Albero su cui ogni arco è etichettato con una lettera, sulle foglie parole complete con le loro posizioni. Sui nodi intermedi lettere, parole parziali, ma anche altre parole, più corte di altre che si troveranno sotto di loro. In ogni nodo oltre ad una stringa si trova anche una lista di parole.

> Fissato un nodo tutte le parole che si trovano nello stesso sottoalbero hanno in comune un prefisso calcolato camminando sull'albero a partire dalla radice

#x013 Cosa succede se voglio inserire una nuova parola? nel punto in cui fallisce la ricerca aggiungo un nodo di split con un arco uscente etichettato con la lettera che caratterizza la parola già presente e il secondo arco uscente etichettato con la lettera caratterizzante la parola da aggiungere.

Nel caso peggiore costa *m*, non dipende dalla dimensione del vocabolario.

# Dettagli sull'inverted index
Un indice è il contrario di una ricerca lineare o sequenziale. Quest'ultima viene usata solo se il dataset è volatile, oppure se si sta esplorando il dataset (eg. crawler)

Voglio eseguire la query: opere di Shakespare che contengono Brutus and Calpurnia but not Cleopatra

Uso una **matrice di incidenza** dove sulle righe stanno i personaggi, mentre sulle colonne le opere, per ogni cella un valore binario che rappresenta presenza o assenza del personaggio nell'opera.

#x014 
Le matrici di incidenza non scalano. Sono grandi entry * documenti
Le matrici di incidenza sono tipicamente sparse, tante più sparse quanti sono i documenti su cui indicizzo.

Gli inverted index tengono traccia solo degli 1; come entry uso le parole, che puntano a liste di documenti che le contengono. Struttura dati orientata alla parola.

Non è sicuramente una struttura dati statica -> **posting list** -> è una lista di *document IDs*

## Definizione
>Meccanismo orientato alla parola per indicizzare una collazione di testi al fine di velocizzare la ricerca.

Si compone di due elementi:
- Vocabolario: insieme di tutte le parole contenute nei testi
- Posting list o lista delle occorrenze: per ogni parola la posizione dell'occorrenza
	- document based: lista di documenti con la corrispondente *tf* (term-frequency) all'interno del documento. Solitamente si memorizzano anche informazioni aggiuntive che indicano l'importanza del termine, ad esempio. In Google se la parola si trova nel corpo o nel testo.
	- word based: lista di documenti con la posizione corrispondente (utile per word-retrieval, più fine)

## Heap's law
Legge appartenente alla teoria dell'informazione.

Un vocabolario cresce con $O(n^b) : 0 \lt b \lt 1$. Solitamente $b = 0.4/0.5$

Cresce con un andamento semi-logaritmico fino ad arrivare a un plateau in cui si esaurisce il vocabolario.

La dimensione si può ridurre facendo stemming o lemmatization

Ad esempio, nella collezione TREC-3, lo spazio richiesto dal dizionario per 1Gb di testo è di soli 5Mb.

Lo spazio extra del word-based è lineare nella documentazione del dataset, in particolare si aggira intorno al 40%.
Risparmio dal 20% al 40% con un document-based inverted index.

# Memorizzazione del vocabolario
#Ricorda che ogni struttura dati non lineare deve essere serializzata per poterna tenere in memoria.

Cosa succede se saturo la memoria?

#Vedi sort-merge join

Solitamente si mantiene in vocabolario separato dalle posting list. In particolare voglio che il vocabolario sia caricato in memoria principale, mentre le posting list in memoria principale.
Quando voglio accedere alla lista di documenti che contengono una parola entro nel vocabolario, mediante una ricerca dicotomica, trovo la posting list e accedo a questa.

- Sul vocabolario posso costruire il Trie, che ha un costo di accesso pari alla lunghezza della parola. Mediamente le parole sono lunghe 6 lettere. Overhead.
- Il B+ tree ha un costo di accesso logaritmico con base m maggiore di 2.
- L'hash non è order perserving, quindi non posso fare *range query*

Il vocabolario è strutturato come array ordinato con *offset, dimensione* della posting list corrispondente.

## Google inverted index
- distribuito su circa 3M di server
- l'indice è stato partizionato in più blocchi, chiamati *shards*
- ogni shard su più repliche

#Vedi Caffeine, in nuovo algoritmo di ricerca di Google, che fa continuo crawling e updating

# Ricerca su inverted index
#Vedi: ricerche booleane, proximity queries

1. ricerca sul vocabolario
2. recupero delle occorrenze

Tipi di ricerca:
- single words queries
- prefix and range queries (eg: tutte le posting lists delle parole comprese tra *parola iniziale* e *parola finale*). Queste query possono essere risolte con tutte le strutture viste, tranne hash.

## Boolean retrieval
Data una query booleana a parso secondo la grammatica degli operatori logici e costruisco l'albero sintattico. Ogni foglia è una parola. (Nella radice avrò l'ultima operazione da eseguire)

Ripercorro l'albero sintattico e applico l'operazione inclusa nel nodo:
- AND intersezione
- OR unione

Un algoritmo non primitivo di unione, intersezione e differenza costa O(N) e usa due puntatori per scorrere le due posting lists.

## Contiguity check algorithm for phrasal retrieval
Premessa: devo avere un inverted index word based.

Se ho la query "computer science engineering" voglio tutti i documenti con sia *computer* che *science*.
- applico la query *computer AND science AND engineering*
- per ogni parola recupero la posting list, ottengo il set di documenti D
- prendo la lista con il minor numero di occorrenze e la fisso
- per ogni posizione della lista più corta cerco nelle altre liste la contiguità. #x004 

Dato un set di documenti D in cui compaiono tutte le keyword $(k_1, k_2, k_3, ..., k_m)$ della frase:
- per ogni documento d di D
	- per ogni parola ottengo la lista di occorrenze per il documento d

#Vedi Lucene, da cui derivano Solr e elasticsearch. È l'inverted index di Apache
#Vedi tecniche di ricerca su indici compressi