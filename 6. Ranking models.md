# Introduzione
>Un algoritmo di ranking implementa un **modello di IR** - un framework *concettuale* che assegna ad ogni coppia documento-query un valore reale di similarità.


>Un modello di IR è una tripla $(D, Q, R(q_j, d_j))$ in cui:
> - D è l'insieme composto dalle rappresentazioni logiche dei documenti (text items)
> - Q è l'insieme composto dalle rappresentazioni logiche delle query (**UIN** - User Information Need)
> - R funzione di ranking. Ad ogni coppia di $D \times Q$ associa un numero reale che misura la similarità. Il codominio è \[0, 1] oppure \[0, +inf]. Valori alti corrispondono a alte similarità. I risultati sono mostrati in ordine inverso.

La rappresentazione logica impatta sull'interpretazione dei documenti. Ad esempio la struttura di un articolo scientifico può far prediligere un match sul titolo piuttosto che un match sull'abstract o sul body.

Un documento strutturato deve quindi essere salvato splittandolo in più field se interessa mantenere la struttura.

La UIN viene tradotta in una query in base al sistema e al linguaggio specifico.

>Un modello di IR è un formalismo per astrarre/idealizzare un sistema più complesso, che tiene conto (il sistema reale) anche di requisiti non funzionali come implementazione e performance.

## Tassonomia dei modelli IR
Proprietà documenti:
- testo
- lin (es. PageRank)
- multimedia

Modelli classici:
- booleani
- vettoriali
- probabilistici

Modelli per il web:
- PageRank
- HITS - Hub (pagine con tanti link uscenti, poco autorevoli) & Authorities (pagine con tanti link entranti, molto autorevoli)

Questi si suddividono in:
- insiemistici
	- fuzzy
	- extended boolean
	- set-based
- algebrici
	- generalized vector
	- neural network
	- ...
- probabilistici
	- LLM
	- BM25

Il multimedia ranking è un discorso a parte che fa uso di: image retrieval, audio e music retrieval, video retrieval.

# Similarità
>La similarità è la qualità che rende una persona o una cosa come (simile a) un'altra

Com'è definita la similarità? dipende dai criteri scelti. Quali sono? colore, tessitura (texture) e forme di un'immagine? Oppure il soggetto rappresentato dall'immagine?

A **similarità** alte corrispondono oggetti **simili**; a ***dissimilarità*** alte corrispondono oggetti **diversi** tra loro; la distanza è una misura di dissimilarità, per questo dissimilarità e distanza sono usati intercambiabilmente.
Eg: tra due immagini identiche il valore di dissimilarità è uguale a zero.

Perchè misurarla?
- classificazione: dato un elemento non etichettato (unlabeled), assegnargli una classe tra due o più classi predefinite
- clustering: trovare raggruppamenti che aggreghino elementi simili e distanzino alementi dissimili
- **query by content**: trovare tutti l'elemento "più vicino" alla query richiesta

Per ottenere una misura di similarità/dissimilarità necessito di alcune feature, contenute nella rappresentazione logica dell'entità in questione (ricorda D e Q). Le feature vengono estratte:
- generation -> dati derivati a partire da più dati elementari
- cleaning -> rimozione rumore e outliers (anomalie)
- normalization -> vengono riportate sulla stessa scala, o scale confrontabili
- reduction -> ad esempio se il punto di partenza sono immense matrici

# Classical IR models
>Il modello classico prevede la rappresentazione logica dei documenti e della query come una *bag of index terms* (insieme di parole significative per il documento, per la definizione vedi sotto)

## Bag of words
La rappresentazione vettoriale dei documenti non tiene in considerazione l'ordine delle parole nel documento. Tiene conto della presenza multipla di una parola in un testo. La struttura si può comunque conservare.

Due frasi diverse potrebbero essere rappresentate dallo stesso vettore.
## Intex terms
>**Index term**: parola - principalmente nomi -, che subiscono una serie di trasformazioni, la cui semantica aiuta a ricordare i temi principali di un documento. Anche chiamate keyword, subject term, descriptor, ...

## Pesi
Non tutti i termini hanno la stessa utilità nel descrivere il contenuto del documento.
Un peso uguale a 0 corrisponde a *parola non presente*, mentre pesi più alti corrispondono a parola più presente (**maggiore frequenza**) o più rara (**maggior rarità**).

## Mutua indipendenza
I pesi degli index terms sono assunti mutualmente indipendenti. Il peso $w_{ij}$ associato a $(k_i, d_j)$ non ci dice nulla su $(k_{i+1}, d_j)$.

In pratica, viene rimossa la nozione di _contesto_, in favore di una semplificazione del modello di ranking e di una velocità di ricerca maggiore.

# Modello booleano
>Nel modello booleano le query possono essere espresse con operatori logici booleani. Le operazioni insiemistiche sono *crisp*. Il codominio di questa funzione di ranking è $\{0, 1\}$

In sostanza questo modello permette di fare solamente **exact matching**, ovvero *sei rilevante* (nei risultati) o *non sei rilevante* (fuori dai risultati)

Strumenti come `grep`, Spotlight, Windows search, WestLaw ecc. usano un modello booleano

Base: teoria degli insiemi e algebra booleana. I pesi possono assumere il valore 0 o 1.

## Semantica delle operazioni booleane
Questo modello è facilmente implementabile per mezzo di strutture dati come l'inverted index.
- $t_x\ AND\ t_y \Leftrightarrow \{d_i  | w_{ix} = 1\} \cap \{d_i  | w_{iy} = 1\}$
- $t_x\ OR\ t_y \Leftrightarrow \{d_i  | w_{ix} = 1\} \cup \{d_i  | w_{iy} = 1\}$
- $NOT\ t_x \Leftrightarrow \{d_i  | w_{ix} = 0\}$
## Analisi
Vantaggi:
- formalismo chiaro
- semantica precisa

Svantaggi:
- **no ranking**
- **exact matching**
- algebra booleana di nicchia (aka, un utente medio non esprime query con operatori logici)

È il modello adottato da WestLaw.
# Vector space model
>È il modello più moderno di quello booleano. Permette all'utente di cercare testo libero. Ordina i documenti in base al loro grado di similarità con la query.

Rappresenta documenti e query come vettori appartenenti allo stesso spazio vettoriale.
I vettori hanno dimensione $t = |vocabulary|$.

L'assunzione di mutua indipendenza (derivata dai modelli classici) equivale ad avere come garanzia che il prodotto tra vettori che rappresentano parole diverse (generatori dello spazio vettoriale) sia zero.
I termini generano lo spazio vettoriale a t dimensioni, dove t corrisponde al numero di termini univoci nel vocabolario.

In questo modello il **matching parziale** è possibile.

>**Feature projection**: documents, queries, terms is a vector in a high dimensional space

Base:
- spazi vettoriali t-dimensionali
- operatori vettoriali

Questo modello si applica a qualunque oggetto dal quale posso estrarre delle features.
Mi permette di fare clustering.

Lo spazio vettoriale è pari al numero di termini unici del vocabolario.

Come calcoliamo la distanza tra query e documento? che metrica usiamo?

## Similarità coseno o prodotto scalare normalizzato
>Quando il vettore tra gli angoli è 90° la similarità pari a zero, mentre quando coincidono, ovvero angolo uguale z 0°, va a 1.

Due vettori sono ortogonali quando non hanno parole in comune, in questo caso l'angolo è 90°. Due vettori si trovano sulla stessa retta quando condividono gli stessi termini, in questo caso l'angolo è 0°. Due vettori coincidono quando condividono lo stesso parole, con un numero di occorrenze multiple tra i due.

Non è altro che il rapporto tra il prodotto scalare dei vettori e il prodotto delle norme:
$$sim(d_j, q) = \frac{d_j \cdot q}{||d_j||_2 \cdot ||q||_2}=\frac{\sum_{i=1}^t d_{ij} q_{i}}{\sqrt{\sum_{i=1}^t d_{ij}^2} \sqrt{\sum_{i=1}^t q_{i}^2}}$$
- Il numeratore va a zero se i vettori sono ortogonali
- Se i vettori sono uguali il risultato è 1: il numeratore diventa $tw^2$, il denominatore $\sqrt{tw^2}\sqrt{tw^2} = tw^2$
- Il denominatore è un fattore di normalizzazione del prodotto scalare, per mantenere il risultato tra 0 e 1
- $||q||$ non influenza il ranking -> è uguale per tutti i documenti, la potrei togliere dalla formula. Infatti continua a valere $sim(q, d_i) < sim(q, d_j)$ indipendentemente dal quel coefficiente. Ma è utile conoscere il limite superiore per fare range similarity query.
- $||d_j||$ è una normalizzazione nello spazio dei documenti (_normalized inner product_). Abbassa il valore di similarità se il documento contiene tanti valori che non matchano ("fanno rumore").

#Nota che in un range tra 0 e 1 la granularità è piuttosto grezza, soprattutto quando il numero di parole chiave è molto esiguo rispetto al numero di parole nei documenti.

# Term weights
>Rilassiamo i vincolo *crisp* (il termine c'è o non c'è) dando un peso ai termini. Rimuoviamo la supposizione che tutti i termini abbiano la stessa rilevanza (equa importanza).

## Term frequency
>Prima scelta ovvia: quante volte il termine è presente all'interno del documento. Alte frequenze -> il termine è importante

3 scelte:
- occorrenze grezze: $count(t_i, d_j)$
- frequenza: $tf(t_i, d_j) = \frac{count(t_i, d_j)}{\sum_t count(t, d_j)}$ dove il denominatore è il numero totale di termini nel documento _j_
- frequenza normalizzata: $tf\_norm(t_i, d_j) = \frac{count(t_i, d_j)}{max_i count(t_i, d_j)}$
- frequenza compressa (*damped frequency*): $\begin{cases} 1+log_{10}(freq(t_i, d_j))\ se\ freq(t_i, d_j) > 0 \\ 0\ altrimenti\end{cases}$
## Document frequency
>Misura la rarità di un termine all'interno di un corpus di documenti.

Un documento che contiene un termine raro, che coincide con la query, è molto probabilmente un documento importante tra i risultati della query.

Useremo la *df - document frequency* che indica in quanti documenti il termine compare (misura inversa di informatività del termine).
Se compare in tanti documenti è "svalutato": non dobbiamo calcolare _df_, bensì il suo inverso.

$$idf_j = log_{10}{\frac{|D|}{df_j}}$$

#Attenzione formule localmente corrette potrebbero essere globalmente "incorrette" -> non avere l'effetto voluto.

#Nota che è il risultato è slegato da un numero di documento
## TF-IDF
Il peso TF-IDF del termine $i$ nel documento $j$ è il prodotto di TF e IDF:
$$w_{ij} = tf_{ij} \times idf_j$$

Questa formula premia i termini molto frequenti nel documento e rari all'interno della collezione.

#Nota che il fattore IDF non ha rilevanza per query con un solo termine. Inizia ad avere effetto su query con più parole.
## Distanze alternative
- Cosine coefficient
- Dice's coefficient $dice(d_j, q) = \frac{2 \cdot d_j \cdot q}{||d_j||_2^2 \cdot ||q||_2^2}$
- Jaccard measure $jac(d_j, q) = \frac{d_j \cdot q}{||d_j||_2^2 + ||q||_2^2 - d_j \cdot q}$
- Minkowski distance (Euclidean distsance) #Attenzione : misura di distanza (dissimilarità)

## Vantaggi e svantaggi del modello vettoriale
Vantaggi:
- il **peso** dei termini migliora le performance (efficacia) di retrieval
- **partial-matching** concesso

Svantaggi:
- modello classico (assunzione: mutuale indipendenza)
- non è robusto rispetto alla polisemia; non cattura la semantica delle parole
- il vocabolario può avere grandi dimensioni, i documenti sono memorizzati come vettori sparsi

## Aspetti pratici e implementazione
Se mantengo in memoria un inverted index, come faccio a calcolare il prodotto vettoriale tra i termini presenti nel documento e i termini della query?
Non posso, è una struttura dati orientata al termine, non al documento.

Avevamo detto: *un modello di IR è un'idealizzazione, un modello astratto* 

Non possiamo fare come descritto fin'ora.

Come applicare la formula coseno sui termini dell'inverted index?
1. è inutile calcolare il prodotto di pesi per termini che l'utente non ha chiesto
2. la query è spesso molto piccola, quindi ha un vettore molto sparso. Parto dai documenti che contengono almeno un termine richiesto nella query, tutti gli altri avranno similarità pari a zero.

Se un termine della query Q appare in media in B documenti (dimensione media della posting list) il costo è: $O(|Q|B)$.
Molto meglio di $O(|V|N)$ - con V vocabolario e N documenti del corpus - dato che Q e B sono molto minori, rispettivamente, di V ed N.

Procedura di retrieval (si assuma un inverted index che, per ogni termine, abbia memorizzato la IDF e, per ogni documento, abbia memorizzato la TF. Inoltre siano note le norme 2 di ogni documento):
- si crei un'hashtable _score_ vuota, con chiave DOC-ID e valore reale
- per ogni termine T della query Q
	- si recuperi la posting list del token T e $IDF_T$
	- si contino le occorrenze K (o la frequenza) di T in Q
	- si pre-calcoli $w = K \cdot IDF_T$
	- per ogni documento D nella posting list
		- si recuperi C - count di T in D
		- se D non è in hashtable, crea entry con valore 0
		- incrementa _score\[D\]_ di $C \cdot IDF_T \cdot w$
- calcola la lunghezza L di Q come radice della somma dei pesi TF-IDF di Q al quadrato
- per ogni documento D di _score_
	- si recuperi la lunghezza Y di D (conosciuta a priori dalle ipotesi)
	- si normalizzi il punteggio ottenuto: $score[D] /= Y*L$
- sort in ordine crescente

# Approccio probabilistico
Problemi del modello booleano e vettoriale:
- il sistema non ha una compresione imprecisa delle query
- non viene tenuta in considerazione la semantica di query e documento

>Si basa su teorie probabilistiche per determinare quanto è probabile che un documento sia rilevante per la query. Retrieval rankato.

Si supponga di avere una variabile dicotomica (binaria) $R_{q, d}$:
- uguale a 1 se d è rilevante per q
- uguale a 0 se d non è rilevante per q
## PRP - Probabilistic Ranking Principle
>Il PRP afferma la rilevanza ha un'interpretazione probabilistica. Se un sistema di retrieval ordina i risultati in ordine decrescente di rilevanza $P(REL|d, q)$, l'efficacia globale del sistema è la più alta ottenibile.

## BMI - Binary Independence Model
Assunzioni:
- variabili dicotomiche -> documento e query sono rappresentati come vettori binari
- indipendenza -> assume indipendenza tra i termini della query e dei documenti come in tutti i modelli classici

Ogni documento è rappresentato da $d_j = (w_{1j}, w_{2j}, ..., w_{Nj})$ con $w_{ij} = 1$ se il termine compare, $0$ altrimenti.

Tutti i modelli di learning moderni utilizzano dei dataset per imparare le probabilità.
Senza ML è necessario trovare statistiche misurabili per valutare la probabilità della rilevanza: tf, idf, length, ..

Notazione:
- $P(R | d, q) = P(R = 1 | d, q)$ probabilità che il documento sia rilevante per la query
- $P(\bar R | d, q) = P(R = 0 | d, q)$ probabilità che il documento NON sia rilevante per la query
- $P(R | d, q) + P(\bar R | d, q) = 1$

- Definisco: $sim(d_j, q) = \frac{P(R|d_j, q)}{P(\bar R|d_j, q)}$ come OR - Odd Ratio
- Applico Bayes ($P(A|B)P(B) = P(B|A)P(A)$): $sim(d_j, q) = \frac{P(d_j | R, q) P(R|q)}{P(d_j | \bar R, q) P(\bar R|q)}$ dove $P(d_j|R, q)$ è la probabilità di selezionare il documento $d_j$ dall'insieme dei rilevanti per la query $q$
- Assumendo $P(R, q) = P(\bar R, q)$, dato che non dipendono dal documento, li elido
- $sim(d_j, q) \approx \frac{P(d_j | R, q)}{P(d_j | \bar R, q)}$
- Assumendo l'indipendenza dei termini possiamo applicare Naive Bayes: $sim(d_j, q) \approx \frac{\prod_{w_{ij}=1}P(k_i|R, q) \times \prod_{w_{ij}=0}P(\bar k_i|R, q)}{\prod_{w_{ij}=1}P(k_i|\bar R, q) \times \prod_{w_{ij}=0}P(\bar k_i|\bar R, q)}$

## Bilancio modello probabilisitico
Vantaggi: i documenti sono ordinati in ordine decrescente per probabilità di importanza rispetto alla query.

Svantaggi:
- inizializzazione degli insiemi dei rilevanti e dei non rilevanti
- pesi binari

# Comparison of classical models
Modello booleano:
- modello classico più debole
- non è in grado di fare ranking

Modello probabilistico:
- è in grado di fare ranking
- #Completa problemi con informazioni sparse?

# Modelli alternativi
Esistono modelli alternativi:
- Fuzzy set model
- BM25. Usato la Lucene e Whoosh. Supera i limiti del BIM di assegnare pesi binari o dell'assenza di pesi nel modello probabilistico.

## Fuzzy
Esiste un isomorfismo tra teoria booleana e logica booleana:
>La **fuzzy set theory** è un superset della logica booleana. Supera la rigidità della logica booleana, in cui ogni affermazione può essere solamente vera o falsa, con il trade-off tra significato e precisione. Riesce a gestire l'incertezza, la vaghezza e l'imprecisione.

>La **fuzzy logic** estende la logica booleana includendo operazioni che riguardano insiemi *sfumati*
### Insiemi fuzzy
>**Crisp set**: basato sull'assunzione attribuita ad Aristotele che *non esiste cosa terza* (ogni elemento o appartiene o non appartiene ad un insieme A)

La *funzione caratteristica* è quella funzione che ritorna 1 se un elemento appartiene ad un insieme, 0 se esso non gli appartiene.

>**Fuzzy set**: si definisce una *membership function* che accetta un'appartenenza parziale ad un insieme.

Non ci sono confini ben definiti. La funzione di appartenenza è tipicamente una curva simil-sigmoidale (curva logistica).
### Operatori fuzzy
$$f_{A \cup B} (x) = max[f_A(x), f_B(x)]$$
$$f_{A \cap B} (x) = min[f_A(x), f_B(x)]$$
$$f_{\neg A} (x) = 1-f_A(x)$$

Si basa sullo stesso range di valori della teoria probabilistica, ma usa due approcci completamente diversi.

Query composte useranno le membership function di unione e intersezione.

### Nell'information retrieval
Ogni termine $t_i$ della query Q definisce un insieme fuzzy $D_{t_i}$.
Ogni documento $d$ ha un grado di appartenenza a questo insieme: $\mu_{D_{t_i}}$
L'appartenenza all'intersezione di tutti gli insiemi dei termini $\mu_{D_{t_i} \cap ... \cap D_{t_n}} = sim(Q_{AND}, d)$, calcolata come massimo tra i gradi di appartenenza.
L'appartenenza all'unione degli insiemi di termini $\mu_{D_{t_i} \cup ... \cup D_{t_n}} = sim(Q_{OR}, d)$ è calcolata come minimo grado di appartenenza.
## BM25
Best Match 25 o Okapi. Modello probabilistico di tipo bag of words.

Il BIM fallisce per documenti in cui i termini si ripetono più volte o per documenti dalla lunghezza variabile. Pensato per documenti di lunghezza consistente. Il BM25 tiene conto di questo.

Idea: includere nel modello probabilistico frequenza dei termini e rarità.

>Lo score per il documento d è chiamato RSV - Retrieval Status Value - ed è la somma pesata delle IDF della query

$$RSV_d = \sum_{t \in q} log \frac{N}{df_t} $$

Migliorando la formula con la lunghezza dei documenti:
$$RSV_d = \sum_{t \in q} log [\frac{N}{df_t}] \frac{(k_1+1)tf_{td}}{k_1((1-b) + b \times (L_d / L_{avg})) + tf_{td}} \frac{(k_3+1) tf_d}{k_3 + tf_{tq}}$$

#Nota k1, k3 e bono parametri di cui può essere fatto tuning: k1 controlla lo scaling della frequenza del documento; b controlla o scaling della lunghezza del documento (L); k3 controlla lo scaling della frequenza nella query.

Lucene e Whoosh usano il BM25F. Si può comunque cambiare il modello con il pacchetto Similarity per Lucene e dall'idx searcher per Python