# Introduzione
>Un algoritmo di ranking implementa un modello di IR - Information Retrieval: un framework concettuale che assegna ad ogni coppia documento-query un valore reale di similarità.


>Un modello di IR è una tripla $(D, Q, R(q_j, d_j))$ in cui:
> - D è l'insieme composto dalle rappresentazioni logiche dei documenti (text items)
> - Q è l'insieme composto dalle rappresentazioni logiche delle query (**UIN** - User Information Need)
> - R funzione di ranking. Ad ogni coppia di $D \times Q$ associa un numero reale che misura la similarità. Il codominio è [0, 1] oppure [0, +inf]. Valori alti corrispondono a alte similarità. I risultati sono mostrati in ordine inverso.

La rappresentazione logica impatta sull'interpretazione dei documenti. Ad esempio la struttura di un articolo scientifico può far prediligere un match sul titolo piuttosto che un match sull'abstract o sul body.

Un documento strutturato deve quindi essere salvato splittandolo in più field se interessa mantenere la struttura.

La UIN viene tradotta in una query in base al sistema e al linguaggio specifico.

>Un modello di IR è un formalismo per descrivere un sistema più complesso, che tiene conto anche di requisiti non funzionali come implementazione e performance.

## Tassonomia dei modelli IR
Proprietà documenti:
- testo
- lin (es. PageRank)
- multimedia

Modelli classici:
- booleani
- vettoriali
- probabilistici

Questi si suddividono in:
- insiemistici
	- fuzzy
	- extende boolean
	- set-based
- algebrici
	- generalized vector
	- neural network
	- ...
- probabilistici
	- LLM
	- BM25

Il multimedia ranking è un discorso a parte che fa uso di: image retrieval, audio e musci retrieval, video retrieval.

# Similarità
>La similarità è la qualità che rende una persona o una cosa come (simile a) un'altra

Com'è definita la similarità? dipende dai criteri scelti. Quali sono? colore, tessitura (texture) e forme di un'immagine? Oppure il soggetto rappresentato dall'immagine?

A similarità alte corrispondono oggetti simili; a dissimilarità alte crossipondono oggetti diversi tra loro. 
Eg: tra due immagini identiche il valore di dissimilarità è uguale a zero.

Perchè misurarla?
- classificazione: dato un elemento non etichettato (unlabeled), assegnargli una classe tra due o più classi predefinite
- clustering: trovare raggruppamenti che aggreghino elementi simili e distanzino alementi dissimili
- query by content: trovare tutti gli elementi "vicini" alla query richiesta

Per ottenere una misura di similarità/dissimilarità necessito di alcune feature. Le feature venno estratte:
- generation -> dati derivati a partire da più dati elementari
- cleaning -> rimozione rumore e outliers (anomalie)
- normalization -> vengono riportate sulla stessa scala, o scale confrontabili
- reduction -> ad esempio se il punti di partenza sono immense matrici

#Vedi fuzzy logic
# Classical IR models
Rappresentazione logica dei documenti: bag of words
#Completa 

## Bag of words
La rappresentazione vettoriale dei documenti non tiene in considerazione l'ordine delle parole nel documento. Tiene conto della presenza multipla di una parola in un testo. La struttura si può comunque conservare.

Due frasi diverse potrebbero essere rappresentate dallo stesso vettore.
## Intex terms
Index term: parola, che subisce una serie di trasformazioni, la cui semantica aiuta a ricordare i temi principali di un documento. Sono principalmente nomi.

## Pesi
Non tutti i termini hanno la stessa utilità nel descrivere il contenuto del documento.
Un peso uguale a 0 corrisponde a *parola non presente*, mentre pesi più alti corrispondono a parola più presente (**maggiore frequenza**) o più rara (**maggior rarità**).

## Mutua indipendenza
I pesi degli index terms sono assunti mutualmente indipendenti. Il peso $W_{ij}$ associato a $(k_i, d_j)$ non ci dice nulla su $(k_i, d_{j+1})$

# Modello booleano
>Nel modello booleano le query possono essere espresse con operatori logici booleani. Le operazioni insiemistiche sono *crisp*. Il codominio di questa funzione di ranking è $\{0, 1\}$

In sostanza questo modello permette di fare solamente **exact matching**, ovvero *sei rilevante* (nei risultati) o *non sei rilevante* (fuori dai risultati)

Strumenti come `grep`, Spotlight, Windows search, WestLaw ecc. usano un modello booleano

Base: teoria degli insiemi e algebra booleana. I pesi possono assumere il valore 0 o 1

Vantaggi:
- formalismo chiaro
- semantica precisa

Svantaggi:
- no ranking
- algebra di Bool di nicchia

# Vector space model
Rappresenta documenti e query come vettori appartenenti allo stesso spazio vettoriale.
L'assunzione di mutua indipendenza (derivata dai modelli classici) equivale ad avere come garanzia che il prodotto scalare tra i due vettori sia uguale a zero.

I termini generano lo spazio vettoriale a N dimensioni, dove N corrisponde al numero di termini univoci.

In questo modello il **matching parziale** è possibile.

>**Feature projection**: documents, queries, terms is a vector in a high dimensional space

Base:
- spazi vettoriali t-dimensionali
- operatori vettoriali

Questo modello si applica a qualunque oggetto dal quale posso estrarre delle features.
Mi permette di fare clustering.

Lo spazio vettoriale è pari al numero di termini unici del vocabolario.

Come calcoliamo la distanza tra query e documento? che metrica usiamo?

## Similarità coseno o prodotto scalare normalizzato
>Quando il vettore tra gli angoli è 90° la similarità pari a zero, mentre quando coincidono va a 1 (massimo).

Due vettori sono ortogonali quando non hanno parole in comune. Due vettori si trovano sulla stessa retta quando condividono gli stessi termini, indipendentemente dalla frequenza.

Non è altro che il rapporto tra la norma della proiezione del primo vettore sul secondo con il primo vettore:
$$sim(d_j, q) = \frac{d_j \cdot q}{|d_j| \times |q|}=\frac{\sum_{i=1}^t w_{ij} w_{iq}}{\sqrt{\sum_{i=1}^t w_{ij}^2} \sqrt{\sum_{i=1}^t w_{iq}^2}}$$
- Il numeratore va a zero se la query contiene termini che il documento non contiene e il documento contiene termini non utili per la query.
- Se i vettori sono uguali il risultato è 1: il numeratore diventa $tw^2$, il denominatore $\sqrt{tw^2}\sqrt{tw^2} = tw^2$
- Il denominatore è un fattore di normalizzazione del prodotto scalare, per mantenere il risultato tra 0 e 1
- $|q|$ influenza il ranking -> è uguale per tutti i documenti, la potrei togliere dalla formula. Infatti continua a valere $sim(q, d_i) < sim(q, d_j)$ indipendentemente dal quel coefficiente. Ma è utile conoscere il limite superiore per fare range similarity query.
- $|d_j|$ è una normalizzazione nello spazio dei documenti. Abbassa il valore di similarità se il documento contiene tanti valori che non matchano ("fanno rumore").

#Nota che in un range tra 0 e 1 la granularità è piuttosto grezza, soprattutto quando il numero di parole chiave è molto esiguo rispetto al numero di parole nei documenti.

# Term weights
>Rilassiamo i vincolo *crisp* (il termine c'è o non c'è) dando un peso ai termini. Rimuoviamo la supposizione che tutti i termini abbiano la stessa rilevanza (equa importanza).

## Term frequency
>Prima scelta ovvia: quante volte il termine è presente all'interno del documento. Alte frequenze -> il termine è importante

3 scelte:
- frequenza grezza: $freq_{ij} = occurrences$ del termine *k_i* nel documento *d_j*
- frequenza normalizzata: $freq_{ij} = \frac{freq{ij}}{max_i freq_{ij}}$
- frequenza compressa (*dampen*): $freq_{ij}= \begin{cases} \end{cases}$

## Document frequency
>Misura la rarità di un termine all'interno di un corpus di documenti.

Un documento che contiene un termine raro, che coincide con la query, è molto probabilmente un documento importante tra i risultati della query.

Useremo la *df - document frequency* che indica in quanti documenti il termine compare (misura inversa di informatività del termine). Se compare in tanti documenti è "svalutato": dobbiamo calcolare l'inverso.

$$idf_i = log{\frac{N}{df_i}}$$

#Attenzione formule localmente corrette potrebbero essere globalmente "incorrette" -> non avere l'effetto voluto.

#Nota che è il risultato è slegato da un numero di documento
## TF-IDF
Il peso TF-IDF del termine $i$ nel documento $j$ è il prodotto di TF e IDF:
$$w_{ij} = tf_{ij} \times idf_i$$

Questa formula premia i termini molto frequenti nel documento e rari all'interno della collezione.

## Distanze alternative
- Cosine coefficient
- Dice's coefficient
- Jacquard measure
- Minkowski distance (Euclidean distsance) #Attenzione : misura di distanza (dissimilarità)
#Completa per caso pesato e binario

## Vantaggi e svantaggi del modello vettoriale
Vantaggi:
- il peso dei termini migliora le performance di retrieval
- partial-matching

Vantaggi:
- modello classico (assunzione: mutuale indipendenza)
- non è robusto rispetto alla polisemia

# Aspetti pratici e implementazione
Se mantengo in memoria un inverted index, come faccio a calcolare il prodotto vettoriale tra i termini presenti nel documento e i termini della query?
Non posso, è una struttura dati orientata al termine, non al documento.

Avevamo detto: *un modello di IR è un'idealizzazione, un modello astratto* 

Non possiamo fare come descritto fin'ora.

Come applicare la formula coseno sui termini dell'inverted index?
1. è inutile calcolare il prodotto di pesi per termini che l'utente non ha chiesto
2. la query è spesso molto piccola, quindi ha un vettore molto sparso. Parto dai documenti che contengono almeno un termine richiesto nella query.

Se un termine appare in media in B documenti (dimensione media della posting list) il costo è: $O(|Q|B)$. Molto meglio di $O(|V|N)$ dato che Q e B sono molto minori di V ed N

## HashTable
#Completa 

# Approccio probabilistico
>Si basa su teorie probabilistiche. Retrieval rankato.

Si supponga di avere una variabile dicotomica (binaria).
## Probabilistic Ranking Principle
Ad alte rilevanze corrispondono documenti che matchano bene la query. Rilevanze basse fanno finire i documenti in fondo -> Ordinamento decrescente in base alla rilevanza.

## BMI - Binary Independence Model
- Binary: variabile dicotomica
- Independence: assume indipendenza tra i termini della query come in tutti i modelli classici
Usato nel BM25

Termini di vettori e query sono rappresentati come vettori binari: questo modello non ammette pesi.

Ogni documento è rappresentato da $d_j = (w_{1j}, w_{2j}, ..., w_{Nj})$ con $w_{ij} = 1$ se il termine compare, $0$ altrimenti.

Tutti i modelli di learning moderni utilizzano dei dataset per imparare le probabilità.
Senza ML è necessario trovare statistiche misurabili per valutare la probabilità della rilevanza.

Notazione:
- $P(R | d, q) = P(R = 1 | d, q)$ probabilità che il documento sia rilevante per la query
- $P(\bar R | d, q) = P(R = 0 | d, q)$ probabilità che il documento NON sia rilevante per la query
- $P(R | d, q) + P(\bar R | d, q) = 1$

- Definisco: $sim(d_j, q) = \frac{P(R|d_j, q)}{P(\bar R|d_j, q)}$ (OR - Odd Ratio)
- Applico Bayes: $sim(d_j, q) = \frac{P(d_j | R, q) P(R|q)}{P(d_j | \bar R, q) P(\bar R|q)}$
- Assumendo $P(R, q) = P(\bar R, q)$, dato che non dipendono dal documento, li elido
- $sim(d_j, q) \approx \frac{P(d_j | R, q)}{P(d_j | \bar R, q)}$
#Completa 

## Bilancio modello probabilisitico
Vantaggi: i documenti sono ordinati in ordine decrescente per importanza rispetto alla query

# Comparison of classical models
Modello booleano:
- modello classico più debole
- non è in grado di fare ranking

Modello probabilistico:
- è in grado di fare ranking
- #Completa problemi con informazioni sparse?

# Modelli alternativi
Esistono modelli alternativi:
- Fuzzy set model
- BM25. Usato la Lucene e Whoosh. Supera i limiti del BIM di assegnare pesi binari o dell'assenza di pesi nel modello probabilistico.

## Fuzzy
Esiste un isomorfismo tra teoria booleana e logica booleana:
>La **fuzzy set theory** è un superset della logica booleana. Supera la rigidità della logica booleana, in cui ogni affermazione può essere solamente vera o falsa, con il trade-off tra significato e precisione. Riesce a gestire l'incertezza, la vaghezza e l'imprecisione.

>La **fuzzy logic** estende la logica booleana includendo operazioni che riguardano insiemi *sfumati*


### Insiemi fuzzy
>**Crisp set**: basato sull'assunzione attribuita ad Aristotele che *non esiste la terra di mezzo* (ogni elemento o appartiene o non appartiene ad un insieme A)

La *funzione caratteristica* è quella funzione che ritorna 1 se un elemento appartiene ad un insieme, 0 se esso non gli appartiene.

>**Fuzzy set**: si definisce una *membership function* che accetta un'appartenenza parziale ad un insieme.

Non ci sono confini ben definiti. La funzione di appartenenza è tipicamente una curva simil-sigmoidale.
### Operatori fuzzy
$$f_{A \cup B} (x) = max[f_A(x), f_B(x)]$$
$$f_{A \cap B} (x) = min[f_A(x), f_B(x)]$$
$$f_{\neg A} (x) = 1-f_A(x)$$

Si basa sullo stesso range di valori della teoria probabilistica, ma usa due approcci completamente diversi.

Query composte useranno le membership function di unione e intersezione.

## BM25
Best Match 25

Il BIM fallisce per documenti in cui i termini si ripetono più volte o per documenti dalla lunghezza variabile.

Idea: includere nel modello probabilistico frequenza dei termini e rarità.

>Lo score per il documento d è chiamata RSV - Retrieval Status Value

$$RSV_d = \sum_{t \in q} log \frac{N}{df_t} $$

Migliorando la formula con la lunghezza dei documenti:
$$RSV_d = \sum_{t \in q} log [\frac{N}{df_t}] \frac{(k_1+1)tf_d}{k_1((1-b) + b \times (L_d / L_{avg}))} \frac{(k_3+1) tf_d}{}$$

#Completa denominatore della formula sopra

#Nota k1 e k3 sono parametri di cui può essere fatto tuning

Lucene e Whoosh usano il BM25F. Si può comunque cambiare il modello con il pacchetto Similarity per Lucene e dall'idx searcher per Python