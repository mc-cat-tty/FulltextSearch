„# Thesaurus
*Iponimo*: auto è un iponimo di mezzo di trasporto
*Iperonimo*: mezzo di trasporto è iperonimo di auto

#Ricorda con ipo (sotto) e iper (sopra) - ipovedente, ecc.

> **Polisemia** = relazione tra parole identiche ma con semantica diversa

Esempi di thesaurus:
- Roget (primo dizionario, 1852)
- Wordnet
- INSPEC
- MESH

#Attenzione il plurale di *thesaurus* è *thesauri*
#Vedi Pubmed e MeSH (Ontologia terminologica): https://www.ncbi.nlm.nih.gov/mesh/

Perché usare thesaurus? avere un vocabolario controllato, affidabile, con basso rumore

Non necessari per ricerche generiche, sono utili soprattutto per i campi ristretti/settoriali

## TIT - Thesaurus Index Term
#Attenzione non è detto che un concetto sia espresso da una sola parola

Nei thesaurus il dato strutturato da essi memorizzato è: concetto (unità semantica di base, costituito da una parola, più parole o frasi) - definizione (spiegazione)

TIT relationship -> relazioni di generalizzazione (iperonimia) -  specializzazione (iponimia) e, sullo stesso livello, appartenenza allo stesso oggetto/ambito/ecc.

Esempio di *mouse*, parola polisemica: http://wordnetweb.princeton.edu/perl/webwn?s=mouse&sub=Search+WordNet&o2=&o0=1&o8=1&o1=1&o7=&o5=&o9=&o6=&o3=&o4=&h=

**Grafo bipartito** che collega parole, concetti a *synset*

## Relazioni semantiche tra le parole
- Hypernymy
- Meronymy -> una parte usata per descrivere il tutto: facce per persone (parte del nome)
- Is-value-of -> parte di (oggetti di cui è parte)
- synonymy -> stesso significato

## Creazione di un thesaurus
Manualmente si ha lo svantaggio di:
- interpretazione soggettiva della semantica
- time consuming

Selezione automatica:
- dipende dalla lingua: 1 thesaurus per lingua
- copertura
- tecniche di **Word Sense Disambiguation - WSD**

# Similarità delle parole
Diversa da sinonimia
*World similarities*

Utile per:
- question answering
- machine translation
- modelli generativi
- ...

Es:
- *car* e *bicycle* simili
- *car* e *gasoline* no

È un rilassamento del concetto di sinonimia. Metrica ordinabile e comparabile.

Storicamente due metodi:
- **path-based**: risalendo la gerarchia di iperonimia delle due parole, finchè non si incontrano sotto un "cappello" comune
- **information-content**: quanto i due significati vengono usati in situazioni simili in corpus di riferimento. Quanto appaiono insieme, nello stesso contesto.

## Path-based
### Path distance similarity
Basata sullo shortest-path che connette le semantiche delle parole attraverso una gerarchia *is-a*

$$
sim_{path\_distance} (c_1, c_2) = \frac{1}{shortest\_path(c_1, c_2) +1}
$$
#Nota che il range è  da 0 a 1
#Problema: *shortest_path* può assumere solo valori continui, in N, quindi il valore risultate è sempre più ammassato per i valori alti di *shortest_path*

### Wu-Palmer distance
*Lowest Common Subsumer* (il più specifico antenato comune dei due concetti)
$$
sim\_palmer(c_1, c_2) = \frac{2*depth(LCS(c_1, c_2))}{depth(c_1) + depth(c_2)} 
$$

## Information-content similarities
$$
IC(c) = -log(P(c))
$$
**Information content** o **Shannon information**: livello di sorpresa di trovare il concetto *c* nel corpus del documento
#Nota prova a plottarla

La sorpresa è molto alta (tende a +inf) per probabilità basse. Per la probabilità certa (P(c) = 1) ho sorpresa uguale a zero.

IC è bassa quanto il termine è usato raramente, è alta se il concetto è di uso comune

### Resnik similarity
È basato sull'IC del LCS - Lower Common Subsumer

$$
sim_{resnik}(c_1, c_2) = -logP(LCS(c_1, c_2))
$$

#Vedi paper *Evolution of semantic similarity  - A Survey*

Più i concetti sono distanti tra loro, più il LCS sarà alto, quindi la probabilità di trovarli insieme sarà bassa (ricorda curva -log)

# Word Sense Disambiguation - WSD
Due fasi:
2. determinare tutti i possibili sensi di una parola presente in un testo
3. ranking dei sensi -> l'algoritmo di WSD fornisce una lista di significati possibili, ognuno con la propria confidenza
4. assegnare ogni occorrenza ad un signficato appropriato

La confidenza viaggia nell'intervallo \[0, 1\], dove a valori alti corrisponde una probabilità alta di correttezza.

Serve scegliere un thesaurus e sulla base di questa scelta analizzare il contesto.
- **bag of words**: il contesto è una finestra di parole che circondano la parola da disambiguare
- **relational information approach**: si porta dietro, come sopra il contesto, ma anche la distanza delle parole del contesto dal termine di disambiguare
Il primo approccio si usa solitamente per testi brevi, dove ci si aspetta che tutto il testo parli dello stesso argomento. Per testi lunghi o articolati si usa il secondo approccio.

Il secondo approccio smorza il peso della probabilità attraverso la distanza del termine dalla parola del contesto -> ad esempio mettendo la distanza al denominatore (**inverso della distanza** magari mitigata con il logaritmo)

# Approccio 1
Fissato un nome N da disambiguare. Per ogni senso $S_N$ di N, per ogni significato di ogni parola del contesto, calcolo la confidenza di significato della parola come il valore di similarità più alto tra i due significati -> ovvero prendo la coppia di significati con LCS più basso.
Prodotto cartesiano di tutti i significati di tutte le parole della bag of words.

Più rigorosamente:
Data una lista di termini $t_1, t_2, ..., t_n$ che costituisce il corpo del documento.
- $\forall t_i \in corpus$
- $confidence_s = 0, \forall s_k \in t_i$
- $confidence_{s_k}=0, \forall t_j : t_j \neq t_i$
- $\forall s_z \in t_j$
- $confidence_{t_j} = max\{sin(s_k, s_z) : s_z \in t_j\}$
- $confidence_{s_k} += confidence_{t_j}$
- $confidence_s = max\{confidence_{s_k}\}, s=argmax\{confidence_{s_k} \in t_i\}$
## Query expansion
>Processo di fornire termini supplementari al search engine arricchendo la frase di ricerca con sinonimi dei termini utilizzati per la query


#Vedi YAKE, RAKE