> Gli indici sono strutture dati che accelerano l'accesso (ricerca) di dati, conservate sulla memoria secondaria.

> Gli indici sono strutture dati sopra a un testo (nel nostro caso) che permette di velocizzare la ricerca. Gli indici si costruiscono offline.

Il processo di indicizzazione è un processo separato dal query processing

Gli indici che vengono usati per fare ricerca su dati alfanumerici (ad esempio un codice fiscale) sono chiamati **B+ tree** (*B plus tree*). È la principale tipologia di indice che viene usato per fare ricerche su grandi quantità di dati, perché il costo di accesso è logaritmico (non logaritmo in base due, ma base più alta, che permette performance migliori).

In SQL si costruisce sulle colonne su cui faccio accesso più di frequente.

#x012 Vedi alberi 2-3-4, alberi AVL

L'indicizzazione funziona quando il tasso di modifica della collezione dei dati è di qualche ordine inferiore rispetto al tasso di ricerca: è **semistatica** e di **grandi dimensioni**; ovvero quando il gioco vale la candela. I servizi di streaming non indicizzano.

Tecniche di indicizzazione:
- **inverted indexes**. Composto da vocabolario e occorrenze. Scelta migliore al momento.
- **suffix arrays**. Utilizzati per fare matching di catene proteiche.
- **signature files**. Concorrenti degli inverted indexes ma in disuso.

Cosa dobbiamo considerare?
- search cost +
- space overhead -
- costo di creazione e aggiornamento -

Solitamente il bilancio è positivo per gli inverted indexes.
## Inverted index
> Gli **inverted index** sono dizionari che contengono come chiave una parole e come valore la lista di documenti che la contengono.

## Notazione
- **n** dimensione del text repository. Si ottiene concatenando tutti i caratteri di tutti i token di tutti i documenti contenuti nel database.
- **m** lunghezza della parola da cercare. "letter" è lunga 6
- **M** dimensione della memoria principale, misurata nella stessa unità di misura dei restanti, ad esempio in caratteri.

Costo ricerche:

| nome | costo ricerca | costo inserimento |
|------|---------------|-------------------|
|sorted array|logN|N|
|binary tree|logN|N|
|hash table|1|N|
|B tree|logN|logN|

# Trie o Prefix Tree
Albero su cui ogni arco è etichettato con una lettera, sulle foglie parole complete con le loro posizioni. Sui nodi intermedi lettere, parole parziali, ma anche altre parole, più corte di altre che si troveranno sotto di loro. In ogni nodo oltre ad una stringa si trova anche una lista di parole.

> Fissato un nodo tutte le parole che si trovano nello stesso sottoalbero hanno in comune un prefisso calcolato camminando sull'albero a partire dalla radice

#x013 Cosa succede se voglio inserire una nuova parola? nel punto in cui fallisce la ricerca aggiungo un nodo di split con un arco uscente etichettato con la lettera che caratterizza la parola già presente e il secondo arco uscente etichettato con la lettera caratterizzante la parola da aggiungere.

Nel caso peggiore costa *m*, non dipende dalla dimensione del vocabolario.

# Dettagli sull'inverted index
Un indice è il contrario di una ricerca lineare o sequenziale. Quest'ultima viene usata solo se il dataset è volatile, oppure se si sta esplorando il dataset (eg. crawler)

Voglio eseguire la query: opere di Shakespare che contengono Brutus and Calpurnia but not Cleopatra

Uso una **matrice di incidenza** dove sulle righe stanno i personaggi, mentre sulle colonne le opere, per ogni cella un valore binario che rappresenta presenza o assenza del personaggio nell'opera.

#x014 
Le matrici di incidenza non scalano. Sono grandi entry * documenti
Le matrici di incidenza sono tipicamente sparse, tante più sparse quanti sono i documenti su cui indicizzo.

Gli inverted index tengono traccia solo degli 1; come entry uso le parole, che puntano a liste di documenti che le contengono. Struttura dati orientata alla parola.

Non è sicuramente una struttura dati statica -> **posting list** -> è una lista di *document IDs*

## Definizione
>Meccanismo orientato alla parola per indicizzare una collazione di testi al fine di velocizzare la ricerca.

Si compone di due elementi:
- Vocabolario: insieme di tutte le parole contenute nei testi
- Posting list o lista delle occorrenze: per ogni parola la posizione dell'occorrenza
	- document based: lista di documenti con la corrispondente *tf* (term-frequency) all'interno del documento. Solitamente si memorizzano anche informazioni aggiuntive che indicano l'importanza del termine, ad esempio. In Google se la parola si trova nel corpo o nel testo.
	- word based: lista di documenti con la posizione corrispondente (utile per word-retrieval, più fine)

## Heap's law
Legge appartenente alla teoria dell'informazione.

Un vocabolario cresce con $O(n^b) : 0 \lt b \lt 1$. Solitamente $b = 0.4/0.5$

Cresce con un andamento semi-logaritmico fino ad arrivare a un plateau in cui si esaurisce il vocabolario.

La dimensione si può ridurre facendo stemming o lemmatization

Ad esempio, nella collezione TREC-3, lo spazio richiesto dal dizionario per 1Gb di testo è di soli 5Mb.

Lo spazio extra del word-based è lineare nella documentazione del dataset, in particolare si aggira intorno al 40%.
Risparmio dal 20% al 40% con un document-based inverted index.